{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vipin/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import maybe_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "Files already extracted\n"
     ]
    }
   ],
   "source": [
    "maybe_download.maybe_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 416, 416, 3)\n"
     ]
    }
   ],
   "source": [
    "imsize = (416, 416)\n",
    "pb_dir = './ssd_inception_v2_coco_2017_11_17/frozen_inference_graph.pb'\n",
    "log_dir = './tmp/'\n",
    "img_dir = './Test-Images/'\n",
    "vid_out_path = './Test-Images/Test-Video/Results'\n",
    "img_path = []\n",
    "for im_p in os.listdir(img_dir):\n",
    "    if 'jpg' in im_p:\n",
    "        img_path.append(img_dir+im_p)\n",
    "image_fed = []\n",
    "for i in range(len(img_path)):\n",
    "    im_tmp = np.array(Image.open(img_path[i]), dtype=np.uint8)\n",
    "    image_fed.append(im_tmp)\n",
    "image_fed = np.asarray(image_fed)\n",
    "print(image_fed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"image_tensor:0\", shape=(?, ?, ?, 3), dtype=uint8)\n",
      "Tensor(\"detection_boxes:0\", shape=(?, 100, 4), dtype=float32)\n",
      "Tensor(\"detection_scores:0\", shape=(?, 100), dtype=float32)\n",
      "Tensor(\"num_detections:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    with tf.gfile.FastGFile(pb_dir, 'rb') as file:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(file.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "        img = graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_scores = graph.get_tensor_by_name('detection_scores:0')\n",
    "        num_detections = graph.get_tensor_by_name('num_detections:0')\n",
    "        detection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
    "        print(img, detection_boxes, detection_scores, num_detections, sep='\\n')\n",
    "        sess = tf.Session(graph=graph)\n",
    "        file_writer = tf.summary.FileWriter(log_dir, graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2175 360 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:42<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 4) (32, 100) (32,) (32, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vid_inp = './Test-Images/Test-Video/traffic_sample_1.mp4'\n",
    "vid_out = './Test-Images/Test-Video/Results/traffic_sample_1_bbox.mp4'\n",
    "if not os.path.exists(vid_out):\n",
    "    os.mkdir(vid_out_path)\n",
    "num_iter = 67\n",
    "batch_size = 32\n",
    "num_pred = 30\n",
    "video_reader = cv2.VideoCapture(vid_inp)\n",
    "video_writer = cv2.VideoWriter(vid_out, cv2.VideoWriter_fourcc(*'XVID'), 30.0, imsize)\n",
    "nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "print(nb_frames, frame_h, frame_w)\n",
    "\n",
    "\n",
    "def draw_boxes(image_fed, bbox):\n",
    "    \n",
    "    for i in range(best_boxes_roi.shape[0]):\n",
    "        im = np.reshape(image_fed[i], (416, 416, 3))\n",
    "#         fix, ax = plt.subplots()\n",
    "#         ax.imshow(im)\n",
    "#         print(best_boxes_classes[i])\n",
    "        for j in range(num_pred):\n",
    "            if best_boxes_scores[i][j] > 0.15:\n",
    "                x = best_boxes_roi[i][j][1]\n",
    "                y = best_boxes_roi[i][j][0]\n",
    "                x_max = best_boxes_roi[i][j][3]\n",
    "                y_max = best_boxes_roi[i][j][2]\n",
    "#                 rect = patches.Rectangle((x, y), (x_max - x), (y_max - y), linewidth=2, edgecolor='r', facecolor='none')\n",
    "#                 ax.add_patch(rect)\n",
    "                cv2.rectangle(im, (x,y), (x_max,y_max), (0,255,0), 3)\n",
    "#         plt.show()\n",
    "        video_writer.write(im)\n",
    "\n",
    "\n",
    "for i in tqdm(range(num_iter)):\n",
    "    image_bat = []\n",
    "    for j in range(batch_size):\n",
    "        ret, image = video_reader.read()\n",
    "        image = cv2.resize(image, imsize)\n",
    "        image_bat.append(image)\n",
    "        image_batch = np.asarray(image_bat)\n",
    "    feed_dict = {img:image_batch}\n",
    "    y_p_boxes, y_p_scores, y_p_num_detections, y_p_classes = sess.run([detection_boxes, \n",
    "                                                                       detection_scores, \n",
    "                                                                       num_detections, \n",
    "                                                                       detection_classes], feed_dict=feed_dict)\n",
    "    best_boxes_roi = []\n",
    "    best_boxes_scores = []\n",
    "    best_boxes_classes = []\n",
    "    for i in range(y_p_boxes.shape[0]):\n",
    "        temp = y_p_boxes[i, :num_pred] * imsize[0]\n",
    "        best_boxes_roi.append(temp)\n",
    "        best_boxes_scores.append(y_p_scores[i, :num_pred])\n",
    "        best_boxes_classes.append(y_p_classes[i, :num_pred])\n",
    "    best_boxes_roi = np.asarray(best_boxes_roi)\n",
    "    best_boxes_scores = np.asarray(best_boxes_scores)\n",
    "    best_boxes_classes = np.asarray(best_boxes_classes)\n",
    "    draw_boxes(image_batch, best_boxes_roi)\n",
    "    \n",
    "print(y_p_boxes.shape, y_p_scores.shape, y_p_num_detections.shape, y_p_classes.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
